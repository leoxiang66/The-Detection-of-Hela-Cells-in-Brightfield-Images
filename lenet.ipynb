{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loaded-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compliant-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理函数\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x, [-1, 32, 32, 1])\n",
    "    y = tf.one_hot(y, depth=10)  # one_hot 编码\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amino-doctrine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "pprint(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fresh-relevance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 样本图像周围补0（上下左右均补2个0），将28*28的图像转成32*32的图像\n",
    "paddings = tf.constant([[0, 0], [2, 2], [2, 2]])\n",
    "x_train = tf.pad(x_train, paddings)\n",
    "x_test = tf.pad(x_test, paddings)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "controversial-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_db = train_db.shuffle(10000)  # 打乱训练集样本\n",
    "train_db = train_db.batch(128)\n",
    "train_db = train_db.map(preprocess)\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_db = test_db.shuffle(10000)  # 打乱测试集样本\n",
    "test_db = test_db.batch(128)\n",
    "test_db = test_db.map(preprocess)\n",
    "\n",
    "batch = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adapted-freight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (32, 28, 28, 6)           156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (32, 14, 14, 6)           0         \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (32, 14, 14, 6)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (32, 10, 10, 16)          2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (32, 5, 5, 16)            0         \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (32, 5, 5, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (32, 1, 1, 120)           48120     \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (32, 1, 1, 120)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (32, 120)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 84)                  10164     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, 10)                  850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 创建模型\n",
    "model = keras.Sequential([\n",
    "    # 卷积层1\n",
    "    keras.layers.Conv2D(6, 5),  # 使用6个5*5的卷积核对单通道32*32的图片进行卷积，结果得到6个28*28的特征图\n",
    "    keras.layers.MaxPooling2D(pool_size=2, strides=2),  # 对28*28的特征图进行2*2最大池化，得到14*14的特征图\n",
    "    keras.layers.ReLU(),  # ReLU激活函数\n",
    "    # 卷积层2\n",
    "    keras.layers.Conv2D(16, 5),  # 使用16个5*5的卷积核对6通道14*14的图片进行卷积，结果得到16个10*10的特征图\n",
    "    keras.layers.MaxPooling2D(pool_size=2, strides=2),  # 对10*10的特征图进行2*2最大池化，得到5*5的特征图\n",
    "    keras.layers.ReLU(),  # ReLU激活函数\n",
    "    # 卷积层3\n",
    "    keras.layers.Conv2D(120, 5),  # 使用120个5*5的卷积核对16通道5*5的图片进行卷积，结果得到120个1*1的特征图\n",
    "    keras.layers.ReLU(),  # ReLU激活函数\n",
    "    # 将 (None, 1, 1, 120) 的下采样图片拉伸成 (None, 120) 的形状\n",
    "    keras.layers.Flatten(),\n",
    "    # 全连接层1\n",
    "    keras.layers.Dense(84, activation='relu'),  # 120*84\n",
    "    # 全连接层2\n",
    "    keras.layers.Dense(10, activation='softmax')  # 84*10\n",
    "])\n",
    "model.build(input_shape=(batch, 32, 32, 1))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-annual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 1.0030 - accuracy: 0.6376\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.4793 - accuracy: 0.8280\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.3976 - accuracy: 0.8566\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.3566 - accuracy: 0.8721\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.3260 - accuracy: 0.8814\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.3086 - accuracy: 0.8882\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.2872 - accuracy: 0.8938\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.2738 - accuracy: 0.9002\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.2581 - accuracy: 0.9043\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.2501 - accuracy: 0.9071\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.2405 - accuracy: 0.9116\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.2295 - accuracy: 0.9161\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.2223 - accuracy: 0.9185\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.2181 - accuracy: 0.9185\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.2078 - accuracy: 0.9232\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.2001 - accuracy: 0.9264\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1922 - accuracy: 0.9276\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.1839 - accuracy: 0.9307\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.1782 - accuracy: 0.9342\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1768 - accuracy: 0.9342\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1642 - accuracy: 0.9384\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.1586 - accuracy: 0.9412\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1575 - accuracy: 0.9418\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.1499 - accuracy: 0.9458\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.1483 - accuracy: 0.9437\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.1412 - accuracy: 0.9471\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.1348 - accuracy: 0.9512\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1328 - accuracy: 0.9510\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.1275 - accuracy: 0.9523\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1242 - accuracy: 0.9534\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.1209 - accuracy: 0.9549\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1192 - accuracy: 0.9545\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1094 - accuracy: 0.9602\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.1074 - accuracy: 0.9596\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.1001 - accuracy: 0.9627\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0974 - accuracy: 0.9628\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0928 - accuracy: 0.9649\n",
      "Epoch 38/50\n",
      "282/469 [=================>............] - ETA: 5s - loss: 0.0929 - accuracy: 0.9648"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "# 训练\n",
    "history = model.fit(train_db, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失下降曲线\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "model.evaluate(test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-plaza",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
