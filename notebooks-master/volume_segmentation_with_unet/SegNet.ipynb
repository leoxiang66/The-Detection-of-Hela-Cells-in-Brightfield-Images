{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T09:04:37.652903Z",
     "start_time": "2021-03-19T09:04:37.629904Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a852db948614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy\n",
    "import scipy.io\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T08:54:56.961735Z",
     "start_time": "2021-03-19T08:54:56.911787Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.io' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8df17aa924c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msalinas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/training/img'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msalinas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img/img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msalinas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask/img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.io' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "salinas = scipy.io.loadmat('datasets/training/img')\n",
    "X = salinas['img/img']\n",
    "Y = salinas['mask/img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FastICA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3e698ac4c566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mica\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastICA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_ica\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_ica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FastICA' is not defined"
     ]
    }
   ],
   "source": [
    "ica = FastICA(n_components=3, random_state=0)\n",
    "X_ica = ica.fit_transform(X)\n",
    "X_ica.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ica = np.reshape(X_ica, [217,512,3])\n",
    "X = np.zeros([512,217,3])\n",
    "X[:,:,0] = np.transpose(X_ica[:,:,0])\n",
    "X[:,:,1] = np.transpose(X_ica[:,:,1])\n",
    "X[:,:,2] = np.transpose(X_ica[:,:,2])\n",
    "Y = np.transpose(np.reshape(Y,[217,512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 217, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shapeJe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:,0] = X[:,:,0]/np.max(X[:,:,0])\n",
    "X[:,:,1] = X[:,:,1]/np.max(X[:,:,1])\n",
    "X[:,:,2] = X[:,:,2]/np.max(X[:,:,2])\n",
    "np.max(X[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(('../Desktop/%s.png' % 'Y'), Y*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = 64 \n",
    "img_h = 64  \n",
    " \n",
    "image_sets = X_ica\n",
    "    \n",
    "def rotate(xb,yb,angle):\n",
    "    M_rotate = cv2.getRotationMatrix2D((img_w/2, img_h/2), angle, 1)\n",
    "    xb = cv2.warpAffine(xb, M_rotate, (img_w, img_h))\n",
    "    yb = cv2.warpAffine(yb, M_rotate, (img_w, img_h))\n",
    "    return xb,yb\n",
    "    \n",
    "def blur(img):\n",
    "    img = cv2.blur(img, (3, 3));\n",
    "    return img\n",
    " \n",
    "def add_noise(img):\n",
    "    for i in range(25):\n",
    "        temp_x = np.random.randint(0,img.shape[0])\n",
    "        temp_y = np.random.randint(0,img.shape[1])\n",
    "        img[temp_x][temp_y] = 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(xb,yb):\n",
    "    if np.random.random() < 0.25:\n",
    "        xb,yb = rotate(xb,yb,90)\n",
    "    if np.random.random() < 0.25:\n",
    "        xb,yb = rotate(xb,yb,180)\n",
    "    if np.random.random() < 0.25:\n",
    "        xb,yb = rotate(xb,yb,270)\n",
    "    if np.random.random() < 0.25:\n",
    "        xb = cv2.flip(xb, 1)  # flipcode > 0：沿y轴翻转\n",
    "        yb = cv2.flip(yb, 1)\n",
    "        \n",
    "    if np.random.random() < 0.25:\n",
    "        xb = blur(xb)\n",
    "    \n",
    "    if np.random.random() < 0.2:\n",
    "        xb = add_noise(xb)\n",
    "        \n",
    "    return xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_dataset(image_num, mode):\n",
    "    print('creating dataset...')\n",
    "    g_count = 0\n",
    "#    for i in tqdm(range(1)):\n",
    "    count = 0\n",
    "        #src_img = cv2.imread('./data/src/' + image_sets[i])  # 3 channels\n",
    "        #label_img = cv2.imread('./data/label/' + image_sets[i],cv2.IMREAD_GRAYSCALE)  # single channel\n",
    "    src_img = X*255\n",
    "    label_img = Y\n",
    "    X_height,X_width,_ = src_img.shape\n",
    "    while count < image_num:\n",
    "        random_width = random.randint(0, X_width - img_w - 1)\n",
    "        random_height = random.randint(0, X_height - img_h - 1)\n",
    "        src_roi = src_img[random_height: random_height + img_h, random_width: random_width + img_w,:]\n",
    "        label_roi = label_img[random_height: random_height + img_h, random_width: random_width + img_w]\n",
    "        if mode == 'augment':\n",
    "            src_roi,label_roi = data_augment(src_roi,label_roi)\n",
    "            \n",
    "        visualize = np.zeros((32,32)).astype(np.uint8)\n",
    "        visualize = label_roi *16-1\n",
    "            \n",
    "        cv2.imwrite(('../Desktop/Train/visualize/%d.png' % g_count),visualize)\n",
    "        cv2.imwrite(('../Desktop/Train/src/%d.png' % g_count),src_roi)\n",
    "        cv2.imwrite(('../Desktop/Train/label/%d.png' % g_count),label_roi)\n",
    "        count += 1 \n",
    "        g_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dataset...\n"
     ]
    }
   ],
   "source": [
    "creat_dataset(2000, 'augment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import load_img, array_to_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten,Dense, BatchNormalization, UpSampling2D, Reshape, Permute, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SegNet():  \n",
    "    model = Sequential()  \n",
    "    #encoder  \n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(img_w,img_h,3),padding='same',activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))  \n",
    "    #(128,128)  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(64,64)  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(32,32)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(16,16)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(8,8)  \n",
    "    #decoder  \n",
    "    model.add(UpSampling2D(size=(2,2)))  \n",
    "    #(16,16)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(32,32)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(64,64)  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(128,128)  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(256,256)  \n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), input_shape=(3,img_w, img_h), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(n_label, (1, 1), strides=(1, 1), padding='same'))  \n",
    "    model.add(Reshape((n_label,img_w*img_h)))  \n",
    "    #axis=1和axis=2互换位置，等同于np.swapaxes(layer,1,2)  \n",
    "    model.add(Permute((2,1)))  \n",
    "    model.add(Activation('softmax'))  \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])  \n",
    "    model.summary()  \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val(val_rate = 0.25):\n",
    "    train_url = []    \n",
    "    train_set = []\n",
    "    val_set  = []\n",
    "    for pic in os.listdir(filepath + 'src'):\n",
    "        train_url.append(pic)\n",
    "    random.shuffle(train_url)\n",
    "    total_num = len(train_url)\n",
    "    val_num = int(val_rate * total_num)\n",
    "    for i in range(len(train_url)):\n",
    "        if i < val_num:\n",
    "            val_set.append(train_url[i]) \n",
    "        else:\n",
    "            train_set.append(train_url[i])\n",
    "    return train_set,val_set\n",
    "    \n",
    "# data for training  \n",
    "def generateData(batch_size,data=[]):  \n",
    "    #print 'generateData...'\n",
    "    while True:  \n",
    "        train_data = []  \n",
    "        train_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))): \n",
    "            url = data[i]\n",
    "            batch += 1 \n",
    "            #print (filepath + 'src/' + url)\n",
    "            #img = load_img(filepath + 'src/' + url, target_size=(img_w, img_h))  \n",
    "            img = load_img(filepath + 'src/' + url)\n",
    "            img = img_to_array(img) \n",
    "            # print img\n",
    "            # print img.shape  \n",
    "            train_data.append(img)  \n",
    "            #label = load_img(filepath + 'label/' + url, target_size=(img_w, img_h),grayscale=True)\n",
    "            label = load_img(filepath + 'label/' + url, grayscale=True)\n",
    "            label = img_to_array(label).reshape((img_w * img_h,))  \n",
    "            # print label.shape  \n",
    "            train_label.append(label)  \n",
    "            if batch % batch_size==0: \n",
    "                #print 'get enough bacth!\\n'\n",
    "                train_data = np.array(train_data)  \n",
    "                train_label = np.array(train_label).flatten()  \n",
    "                #train_label = LabelEncoder.fit_transform(train_label)  \n",
    "                train_label = to_categorical(train_label, num_classes=n_label)  \n",
    "                train_label = train_label.reshape((batch_size,img_w * img_h,n_label))  \n",
    "                yield (train_data,train_label)  \n",
    "                train_data = []  \n",
    "                train_label = []  \n",
    "                batch = 0  \n",
    "\n",
    "# data for validation \n",
    "def generateValidData(batch_size,data=[]):  \n",
    "    #print 'generateValidData...'\n",
    "    while True:  \n",
    "        valid_data = []  \n",
    "        valid_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))):  \n",
    "            url = data[i]\n",
    "            batch += 1  \n",
    "            #img = load_img(filepath + 'src/' + url, target_size=(img_w, img_h))\n",
    "            img = load_img(filepath + 'src/' + url)\n",
    "            #print img\n",
    "            #print (filepath + 'src/' + url)\n",
    "            img = img_to_array(img)  \n",
    "            # print img.shape  \n",
    "            valid_data.append(img)  \n",
    "            #label = load_img(filepath + 'label/' + url, target_size=(img_w, img_h),grayscale=True)\n",
    "            label = load_img(filepath + 'label/' + url, grayscale=True)\n",
    "            label = img_to_array(label).reshape((img_w * img_h,))  \n",
    "            # print label.shape  \n",
    "            valid_label.append(label)  \n",
    "            if batch % batch_size==0:  \n",
    "                valid_data = np.array(valid_data)  \n",
    "                valid_label = np.array(valid_label).flatten()  \n",
    "                #valid_label = LabelEncoder.fit_transform(valid_label)  \n",
    "                valid_label = to_categorical(valid_label, num_classes=n_label)  \n",
    "                valid_label = valid_label.reshape((batch_size,img_w * img_h,n_label))  \n",
    "                yield (valid_data,valid_label)  \n",
    "                valid_data = []  \n",
    "                valid_label = []  \n",
    "                batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_601 (Conv2D)          (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_581 (Bat (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_602 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_582 (Bat (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_118 (MaxPoolin (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_603 (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_583 (Bat (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_604 (Conv2D)          (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_584 (Bat (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_119 (MaxPoolin (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_605 (Conv2D)          (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_585 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_606 (Conv2D)          (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_586 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_607 (Conv2D)          (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_587 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_120 (MaxPoolin (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_608 (Conv2D)          (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_588 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_609 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_589 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_610 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_590 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_121 (MaxPoolin (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_611 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_591 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_612 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_592 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_613 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_593 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_122 (MaxPoolin (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_105 (UpSamplin (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_614 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_594 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_615 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_595 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_616 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_596 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_106 (UpSamplin (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_617 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_597 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_618 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_598 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_619 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_599 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_107 (UpSamplin (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_620 (Conv2D)          (None, 16, 16, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_600 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_621 (Conv2D)          (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_601 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_622 (Conv2D)          (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_602 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_108 (UpSamplin (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_623 (Conv2D)          (None, 32, 32, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_603 (Bat (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_624 (Conv2D)          (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_604 (Bat (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_109 (UpSamplin (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_625 (Conv2D)          (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_605 (Bat (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_626 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_606 (Bat (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_627 (Conv2D)          (None, 64, 64, 17)        1105      \n",
      "_________________________________________________________________\n",
      "reshape_17 (Reshape)         (None, 17, 4096)          0         \n",
      "_________________________________________________________________\n",
      "permute_16 (Permute)         (None, 4096, 17)          0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 4096, 17)          0         \n",
      "=================================================================\n",
      "Total params: 31,821,841\n",
      "Trainable params: 31,804,945\n",
      "Non-trainable params: 16,896\n",
      "_________________________________________________________________\n",
      "the number of train data is 1500\n",
      "the number of val data is 500\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "BS = 15\n",
    "n_label = 17\n",
    "args = {'model':[]}\n",
    "filepath = '../Desktop/Train/'\n",
    "model = SegNet()  \n",
    "modelcheck = ModelCheckpoint(args['model'],monitor='val_acc',save_best_only=True,mode='max')  \n",
    "callable = [modelcheck]  \n",
    "train_set,val_set = get_train_val()\n",
    "train_numb = len(train_set)  \n",
    "valid_numb = len(val_set)  \n",
    "print (\"the number of train data is\",train_numb)  \n",
    "print (\"the number of val data is\",valid_numb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=20, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 152s 2s/step - loss: 1.1219 - accuracy: 0.5963 - val_loss: 1.0643 - val_accuracy: 0.6253\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.9920 - accuracy: 0.6311 - val_loss: 1.0047 - val_accuracy: 0.6387\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.9069 - accuracy: 0.6548 - val_loss: 0.9555 - val_accuracy: 0.6475\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.8590 - accuracy: 0.6646 - val_loss: 0.9561 - val_accuracy: 0.6498\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.8147 - accuracy: 0.6756 - val_loss: 0.9063 - val_accuracy: 0.6602\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.7825 - accuracy: 0.6829 - val_loss: 0.8699 - val_accuracy: 0.6641\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.7545 - accuracy: 0.6884 - val_loss: 0.8574 - val_accuracy: 0.6714\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.7330 - accuracy: 0.6932 - val_loss: 0.8268 - val_accuracy: 0.6785\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.7166 - accuracy: 0.6966 - val_loss: 0.8362 - val_accuracy: 0.6782\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.7031 - accuracy: 0.6990 - val_loss: 0.8234 - val_accuracy: 0.6781\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.6916 - accuracy: 0.7016 - val_loss: 0.7967 - val_accuracy: 0.6872\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 152s 2s/step - loss: 0.6799 - accuracy: 0.7044 - val_loss: 0.8038 - val_accuracy: 0.6863\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.6697 - accuracy: 0.7077 - val_loss: 0.7807 - val_accuracy: 0.6919\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.6622 - accuracy: 0.7099 - val_loss: 0.7952 - val_accuracy: 0.6872\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.6547 - accuracy: 0.7128 - val_loss: 0.7921 - val_accuracy: 0.6901\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.6460 - accuracy: 0.7170 - val_loss: 0.7764 - val_accuracy: 0.6928\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.6343 - accuracy: 0.7232 - val_loss: 0.7846 - val_accuracy: 0.6916\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 152s 2s/step - loss: 0.6188 - accuracy: 0.7322 - val_loss: 0.7573 - val_accuracy: 0.7047\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.6009 - accuracy: 0.7424 - val_loss: 0.7612 - val_accuracy: 0.7028\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.5815 - accuracy: 0.7542 - val_loss: 0.7492 - val_accuracy: 0.7118\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.5624 - accuracy: 0.7642 - val_loss: 0.7343 - val_accuracy: 0.7161\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.5401 - accuracy: 0.7755 - val_loss: 0.7180 - val_accuracy: 0.7259\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 156s 2s/step - loss: 0.5209 - accuracy: 0.7843 - val_loss: 0.7295 - val_accuracy: 0.7218\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.5042 - accuracy: 0.7915 - val_loss: 0.7134 - val_accuracy: 0.7332\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.4882 - accuracy: 0.7987 - val_loss: 0.7164 - val_accuracy: 0.7318\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.4754 - accuracy: 0.8040 - val_loss: 0.6978 - val_accuracy: 0.7398\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.4649 - accuracy: 0.8084 - val_loss: 0.7016 - val_accuracy: 0.7391\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.4533 - accuracy: 0.8133 - val_loss: 0.6926 - val_accuracy: 0.7428\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.4413 - accuracy: 0.8183 - val_loss: 0.6850 - val_accuracy: 0.7464\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.4295 - accuracy: 0.8231 - val_loss: 0.6828 - val_accuracy: 0.7494\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(generateData(BS,train_set),steps_per_epoch=train_numb//BS,epochs=EPOCHS,\n",
    "              validation_data=generateValidData(BS,val_set),validation_steps=valid_numb//BS)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-67-40005d6026a4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-40005d6026a4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    validation_data=generateValidData(BS,val_set),validation_steps=valid_numb #BS,callbacks=callable,max_queue_size=1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on SegNet Satellite Seg\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
