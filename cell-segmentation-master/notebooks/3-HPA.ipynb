{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Protein Atlas Featurization\n",
    "\n",
    "\n",
    "In this notebook, we explore the Human Protein Atlas Dataset and discuss the strategy we used to create featurizers using this dataset.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "The dataset that we used for our HPA featurizers is from the [Kaggle Human Protein Atlas Image Classification Challenge](https://www.kaggle.com/c/human-protein-atlas-image-classification). The dataset contains a large number of confocal microscopy imaging of cells. Each sample is represented by four channels: nucleus (blue), microtubules (red), endoplasmic reticulum (yellow) and protein (green). Each sample is also paired with 27 different cell type labels, but for our purpose, only the images were used.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%gui qt5\n",
    "import napari\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example from the dataset\n",
    "\n",
    "The four different channels represent: \n",
    "- Microtubules (Red)\n",
    "- Protein (Green)\n",
    "- Nucleus (Blue)\n",
    "- Endoplasmic Reticulum (Yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'ER' at 0x7f4ce65c6c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = np.load(\"hpa_example.npy\")\n",
    "viewer = napari.view()\n",
    "viewer.add_image(image[0], colormap =\"red\", name=\"Microtubules\", blending=\"additive\")\n",
    "viewer.add_image(image[1], colormap =\"green\", name=\"Protein\", blending=\"additive\")\n",
    "viewer.add_image(image[2], colormap =\"blue\", name=\"Nucleus\", blending=\"additive\")\n",
    "viewer.add_image(image[3], colormap =\"yellow\", name=\"ER\",  blending=\"additive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "After downloading the dataset from Kaggle, we processed and stored all training examples into a HDF5 file. The code we used to generate this file can be found [here](https://github.com/marshuang80/BioSegmentation/blob/master/process_data/hpa_create_hdf5.py)\n",
    "\n",
    "You can specify the input folder of your data and your desired output directory as the following:\n",
    "\n",
    "```\n",
    "python create_hpa_hdf5.py --input_dir \"/home/user/hpa/\" \\\n",
    "                          --output_dir \"/home/user/data/\"\n",
    "```\n",
    "\n",
    "After the HDF5 file is generated, we impletemented a PyTorch Dataset to process these input data for the model [code](https://github.com/marshuang80/BioSegmentation/blob/master/dataset/hpa_dataset.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "To train our featurizer, we have implemented a simple [UNet model](https://arxiv.org/pdf/1505.04597)\n",
    "\n",
    "![](./figs/unet.png)\n",
    "\n",
    "The impletmentation code can be found [here](https://github.com/marshuang80/BioSegmentation/blob/master/model/unet.py)\n",
    "\n",
    "Since segmentify currently only supports black and white images (one color channel) and HPA images have four channels, we can either take the max or mean across the color channels and use the resulting image as input: \n",
    "\n",
    "\n",
    "| Max | Mean | \n",
    "| --- | --- |\n",
    "| ![](figs/hpa_max.png) |  ![](figs/hpa_mean.png) |\n",
    "\n",
    "The choice of mean or max depends on the segmentation target. We have experimented with several output targets:\n",
    "\n",
    "- 1 channel (nucleus channel)\n",
    "- 3 channels (nucleus, microtubles, ER)\n",
    "- 4 channels (nucleu, microtubles, ER and protein)\n",
    "\n",
    "\n",
    "\n",
    "**NEED EDIT**\n",
    "\n",
    "The target channels can be binarized with a threshold (0.5) or leave as original. \n",
    "\n",
    "To train the model, run **train.py** from [BioSegmentation](https://github.com/marshuang80/BioSegmentation) with the right parameters, for example: \n",
    "\n",
    "```\n",
    "python train.py --num_kernel 8 \\\n",
    "                --kernel_size 3\\\n",
    "\t\t        --lr 1e-3 \\\n",
    "\t\t        --epoch 200\\\n",
    "\t\t\t    --train_data /home/user/Nuclei/train.hdf5 \\\n",
    "\t\t\t    --val_data /home/user/Nuclei/val.hdf5 \\\n",
    "\t\t\t    --save_dir ./ \\\n",
    "                --device cuda\\\n",
    "                --optimizer adam\\\n",
    "                --model unet\\\n",
    "                --shuffle False \\\n",
    "                --num_workers 16 \\\n",
    "                --vflip False \\\n",
    "                --hflip False \\\n",
    "                --zoom True \\\n",
    "                --rotate False \\\n",
    "                --batch_size 64 \\\n",
    "                --gpu_ids 0,1,2,3\\\n",
    "                --experiment_name unet_k8_s3_adam\n",
    "```\n",
    "\n",
    "The saved model is called **UNet.pth**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize\n",
    "\n",
    "After the segmentation network is trained and saved, we can then use the trained model as a featurizer by removing the last layer or simply switch the last layer to an identity function. The featurizing code can be found ([here](https://github.com/transformify-plugins/segmentify/blob/master/segmentify/semantic/main.py))\n",
    "\n",
    "The different featurized image can be visualized with the following block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 channel (nucleus)\n",
    "nuclei_features = np.load(\"hpa_1c_max_features.npy\")\n",
    "nuclei_features = np.transpose(nuclei_features, (2,0,1))\n",
    "viewer = napari.view(nuclei_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 channel (nucleus, microtubles, ER)\n",
    "nuclei_features = np.load(\"hpa_3c_mean_features.npy\")\n",
    "nuclei_features = np.transpose(nuclei_features, (2,0,1))\n",
    "viewer = napari.view(nuclei_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 channel (nucleus, microtubles, ER, protein)\n",
    "nuclei_features = np.load(\"hpa_4c_mean_features.npy\")\n",
    "nuclei_features = np.transpose(nuclei_features, (2,0,1))\n",
    "viewer = napari.view(nuclei_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We use the following steps to evaluate our featurizers:\n",
    "- Featurize all images (including train and test)\n",
    "- Pick 20% of the pixels from the training data\n",
    "- Train a Random Forest Classifier using the 20% selected pixels\n",
    "- Predict binary segmentation on test set using trained RFC/\n",
    "- Remove small islands\n",
    "\n",
    "Using the 3 different HPA featurizers, we are able to obtain the results below. The x axis show the number of training examples used, and the y axis is the performance metric (IoU, precision).\n",
    "\n",
    "\n",
    "**1 channel (nucleus) max 8 dimentions**:\n",
    "![](./figs/hpa_1c_8_max.png)\n",
    "\n",
    "**3 channel (nucleus) mean 16 dimentions**:\n",
    "![](./figs/hpa_3c_16_mean.png)\n",
    "\n",
    "**4 channel (nucleus) mean 16 dimentions**:\n",
    "![](./figs/hpa_4c_16_mean.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
