{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizer Performance\n",
    "\n",
    "In this notebook, we compare the performance for each featurizer and discuss each other their pros and cons. \n",
    "\n",
    "## Metric\n",
    "\n",
    "To benchmark our featurizers, we use the following two metrics for evaluation:\n",
    "\n",
    "- IoU\n",
    "\n",
    "<img src=\"./figs/iou.png\" style=\"float: left\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision\n",
    "\n",
    "<img src=\"./figs/precision.png\" style=\"float: left\" width=\"200\"/>\n",
    "Compare IoU of every predicted connected component with every instance segmentation\n",
    "\n",
    "TP if best IoU for a specific prediction is greater than a threshold (IoU values from 0.5 to 1.0 steps 0.05) else FP\n",
    "\n",
    "To generate the connected components, we used the function from scipy [(label)](https://www.pydoc.io/pypi/scipy-1.0.1/autoapi/ndimage/measurements/index.html#ndimage.measurements.label). This function takes any non-zero connected components in input as features and zero values as background. \n",
    "\n",
    "\n",
    "| Before connected component | After connected component | \n",
    "| --- | --- |\n",
    "| ![](./figs/before_cc.png) |  ![](./figs/after_cc.png) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing\n",
    "\n",
    "The raw segmentation from either featurizers achieved acceptable IoU score yet very low precision. Further analysis reavealed that tiny islands of segmentation are contributing to large number of False Positives. We removed all small islands before further evaluation.\n",
    "\n",
    "\n",
    "| Before post processing | After post processing | \n",
    "| --- | --- |\n",
    "| ![](./figs/no_remove_island.png) |  ![](./figs/remove_island.png) |\n",
    "| Before post processing | After post processing |\n",
    "| ![](./figs/b_remove.png) |  ![](./figs/a_remove.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum number of training examples\n",
    "\n",
    "We want to know the minimum number of examples that our users need to label to train a model that is generalizable across their dataset. We have tested the performance of our featurizers when trained with different number of training examples, ranging from 1 to 10. For each trianing example, we pick randomly picked 20% of the pixels for our Random Forest Classifier. \n",
    "\n",
    "Based on our experiments, the performance gain plateaus after 4 examples\n",
    "\n",
    "![](./figs/number_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum percentage of pixels per trianing image\n",
    "\n",
    "After knowing the minimum number of examples needed, we also want to know the minimum percentrage of pixels needed. We have tested the performance of our featurizers when trained with different percentage of trianing pixels, ranging from 0.05 to 1.0. Since the performance is stable with 4 or more examples, we randomly picked 4 training examples to evaluate the performance of varying trianing pixels.\n",
    "\n",
    "Based on our experiments, the performance gain plataus after 10% selected pixels. \n",
    "\n",
    "![](./figs/percent_pixel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to featurize images:\n",
    "\n",
    "We also want to know the time it takes to featurize images using different featurizers. Since the all of the HPA and nuclei featurizers uses the same UNet architecture, we didn't experiement with the run time for each individual settings. We primary tested the time difference between UNet and image filter featurization, as well as 8 vs 16 feature dimentions. \n",
    "\n",
    "|  |  | \n",
    "| --- | --- |\n",
    "| ![](./figs/1_time.png) |  ![](./figs/100_time.png) |\n",
    "\n",
    "\n",
    "Based on the chart on the left, it might seem like the 8 dimentional filter featurizer requires the least amount of time. It is worth noting, however, that most of the run time for UNet featurizer is used to build the network. As we can see from the chart on the right, our UNet feturizer out performance image filter featurizers when scaled up to 100 training examples. The runtime for UNet is even better for users who have access to GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We want to know which featurizer out of all the different configurations produces the best performance.\n",
    "\n",
    "First, we need to determine if we should take the max or mean across channels for the HPA based Unet featurizer:\n",
    "\n",
    "![](./figs/test_max_mean.png)\n",
    "\n",
    "Based on the graph above, the multi channel UNet tend to perform better with mean compression, while the UNet that only outputs the nuclei mask achieved better result with max compression.\n",
    "\n",
    "We also want to know if the performance gain from using more dimentions (16) is enough to compensate with the run time required. For this experiment, we used the mean/max configuration determined from above for our HPA UNet:\n",
    "\n",
    "![](./figs/test_8_16.png)\n",
    "\n",
    "Surprisingly, all the featurizers besides HPA UNet with 3 channels perform better with 8 dimentions instead of 16. This is most likely due to 16 channels overfitting to the dataset used to train the model.\n",
    "\n",
    "Using the optimal configurations (mean/max, 8/16) for each featurizer, we want to determine the best overall model for segmentify:\n",
    "\n",
    "![](./figs/test_overall.png)\n",
    "\n",
    "Even though the Nuclei UNet has by far the best result, it is worth noting that the Nuclei UNet is trained with the same dataset. Another dataset is needed to accruately and unbiasedly evaluate the perfoamnce of Nuclei UNet. \n",
    "\n",
    "The second best featurizer is based on the image filters. However, images from the Nuclei dataset has a strong visual difference between background and target, which is favorable for image filters. Again, another dataset is required to draw a better conclusion.\n",
    "\n",
    "The HPA_4might seem like it has a better performance as compared to HPA_3 based on their average IoUs, but the HPA_3 actually has a much smaller range. In fact, HAP_3 actuall has a higher precision too and run time too.n \n",
    "\n",
    "In conclusion, it is still hard to tell which featurizer is the most suitable for Segmentify. Not only does it depend on the user's usecase, the performance need to be evaluated on more dataset to determine the generalizability of each featurizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
