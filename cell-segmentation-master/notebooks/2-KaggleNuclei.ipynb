{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Nuclei Featurization\n",
    "\n",
    "\n",
    "In this notebook, we explore the 2018 Kaggle Data Science Bowl Dataset and discuss the strategy we used to create a featurizer using this dataset.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "The dataset that we used for our nuclei featurizer is from the [2018 Kaggle Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018). The dataset contains a large number of segmented nuclei images. Each *ImageId* contains the origin image (4 channels) along with it's overall segmentation and each instance segmentation. \n",
    "\n",
    "Since the first three channels of the original image are identical, and the 4th is just the alpha, we only use the first channel to train our featurizer. \n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt5\n",
    "import napari\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example from the dataset\n",
    "\n",
    "Notice that the first 3 channels are identical, and the 4th channel is blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load(\"nuclei_example.npy\")\n",
    "viewer = napari.view(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "After downloading the dataset from Kaggle, all the training examples are stored into a HDF5 file. To simplify the batch training process, only images with the majority size (256x256x4) were kept (334/634).\n",
    "\n",
    "The code we used to generate this file can be found [here](https://github.com/marshuang80/BioSegmentation/blob/master/process_data/create_hdf5.py)\n",
    "\n",
    "You can specify the input folder of your data and your desired output directory as the following:\n",
    "\n",
    "```\n",
    "python create_hdf5.py --input_dir \"/home/user/kaggle-dsbowl-2018-dataset-fixes/stage1_train/\" \\\n",
    "                      --output_dir \"/home/user/data/\"\n",
    "```\n",
    "\n",
    "After the HDF5 file is generated, we impletemented a PyTorch Dataset to process these input data for the model [code](https://github.com/marshuang80/BioSegmentation/blob/master/dataset/dataset.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "To train our featurizer, we have implemented a simple [UNet model](https://arxiv.org/pdf/1505.04597)\n",
    "\n",
    "![](./figs/unet.png)\n",
    "\n",
    "The impletmentation code can be found [here](https://github.com/marshuang80/BioSegmentation/blob/master/model/unet.py)\n",
    "\n",
    "As mentioned above, only the first dimention of the input images were used during training due to redundency. Since we are training for object segmentation instead of instance segmentation, only the whole image mask is used as the network target. \n",
    "\n",
    "| Input | Target | \n",
    "| --- | --- |\n",
    "| ![](figs/input.png) |  ![](figs/target.png) |\n",
    "\n",
    "\n",
    "To train the model, run **train.py** from [BioSegmentation](https://github.com/marshuang80/BioSegmentation) with the right parameters, for example: \n",
    "\n",
    "```\n",
    "python train.py --num_kernel 8 \\\n",
    "                --kernel_size 3\\\n",
    "\t\t        --lr 1e-3 \\\n",
    "\t\t        --epoch 200\\\n",
    "\t\t\t    --train_data /home/user/Nuclei/train.hdf5 \\\n",
    "\t\t\t    --val_data /home/user/Nuclei/val.hdf5 \\\n",
    "\t\t\t    --save_dir ./ \\\n",
    "                --device cuda\\\n",
    "                --optimizer adam\\\n",
    "                --model unet\\\n",
    "                --shuffle False \\\n",
    "                --num_workers 16 \\\n",
    "                --vflip False \\\n",
    "                --hflip False \\\n",
    "                --zoom True \\\n",
    "                --rotate False \\\n",
    "                --batch_size 64 \\\n",
    "                --gpu_ids 0,1,2,3\\\n",
    "                --experiment_name unet_k8_s3_adam\n",
    "```\n",
    "\n",
    "The saved model is called **UNet.pth**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize\n",
    "\n",
    "After the segmentation network is trained and saved, we can then use the trained model as a featurizer by removing the last layer or simply switch the last layer to an identity function. The featurizing code can be found ([here](https://github.com/transformify-plugins/segmentify/blob/master/segmentify/semantic/main.py))\n",
    "\n",
    "The featurized image can be visualized with the following block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_features = np.load(\"nuclei_features.npy\")\n",
    "nuclei_features = np.transpose(nuclei_features, (2,0,1))\n",
    "viewer = napari.view(nuclei_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We use the following steps to evaluate our featurizers:\n",
    "- Featurize all images (including train and test)\n",
    "- Pick 20% of the pixels from the training data\n",
    "- Train a Random Forest Classifier using the 20% selected pixels\n",
    "- Predict binary segmentation on test set using trained RFC\n",
    "- Remove small islands\n",
    "\n",
    "Using this nuclei featurizer, we are able to obtain the results below. The x axis show the number of training examples used, and the y axis is the performance metric (IoU, precision).\n",
    "\n",
    "![](./figs/nuclei_featurize.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
